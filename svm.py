#all necessary imports
import os
import numpy as np
import pandas as pd
import csv
import seaborn as sns

#sklearn model and cv imports
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.naive_bayes import MultinomialNB
from sklearn import tree
from sklearn import svm
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier



#train test split code
# print(os.listdir("../input"))

datac=pd.read_csv('../input/final_with_numeric_label.csv') #load csv, covert to pandas
dataBD=pd.read_csv('../input/BDappsF.csv')
# print(datac.head())
# iris = load_iris()

x=datac.iloc[:,:-1]
y=datac.iloc[:,15]
x_train,x_test, y_train, y_test=train_test_split(x,y,test_size=0.20, random_state = 1)

#printing the shape to verify
# print(x_test.shape)
# print(y_test.shape)

print(x.shape)
print(x.shape[0])

xBD=dataBD.iloc[:,:-1]
yBD=dataBD.iloc[:,15]
xBD_train,xBD_test, yBD_train, yBD_test=train_test_split(xBD,yBD,test_size=0.0)

# print(xBD_train.shape)
# print(yBD_train.shape)

#print(list(dataBD.apkName))

#models code
#svm starts here
print("SVM accuracy is")
svmCLF=SVC()
svmCLF.fit(x_train, y_train)
print(svmCLF.score(x_test, y_test))

#just copied stylo.py code
#knn starts here
print("KNN accuracy is")
knnCLF = KNeighborsClassifier(n_neighbors=5)
knnCLF.fit(x_train, y_train)
print(knnCLF.score(x_test, y_test))

#decision tree starts here
print("Decision tree accuracy is")
dtCLF = tree.DecisionTreeClassifier()
#dtCLF_output = dtCLF.fit(x_train, y_train)
dtCLF.fit(x_train, y_train)
print(dtCLF.score(x_test, y_test))

#svm starts here
# print("SVM with linear kernel accuracy is")
# clf = svm.SVC()
# clf.fit(x_train, y_train)
# print(clf.score(x_test, y_test))
# print("SVM prediction")
# print(clf.predict(xBD_train))

#logistic regression starts here
print("logistic regression accuracy is")
lrCLF = LogisticRegression(multi_class="multinomial", solver="lbfgs", C=5)
lrCLF.fit(x_train,y_train)
print(lrCLF.score(x_test, y_test))

#random forest starts here
print("random forest accuracy is")
X_train, X_test, Y_train, Y_test = train_test_split(x, y , random_state = 1)
rfCLF = RandomForestClassifier(n_estimators=100)
rfCLF.fit(x_train, y_train)
predicted = rfCLF.predict(x_test)
print(accuracy_score(predicted, y_test))


#all classifications reports
svmPRED=svmCLF.predict(x_test)
print("this is the classification report for svm")
print(classification_report(y_test, svmPRED))

knnPRED=knnCLF.predict(x_test)
print("this is the classification report for knn")
print(classification_report(y_test, knnPRED))

dtPRED = dtCLF.predict(x_test)
print("this is the classification report for decision tree")
print(classification_report(y_test, dtPRED))

lrPRED=lrCLF.predict(x_test)
print("this is the classification report for logistic regression")
print(classification_report(y_test, lrPRED))

rfPRED=rfCLF.predict(x_test)
print("this is the classification report for random forest")
print(classification_report(y_test, rfPRED))


#all predictions
print("SVM prediction")
print(svmCLF.predict(xBD_train))
#heroes of 71 re malware bole

print("KNN prediction")
print(knnCLF.predict(xBD_train))

print("Decision Tree prediction")
print(dtCLF.predict(xBD_train))

print("Logistic Regression Prediction")
print(lrCLF.predict(xBD_train))

print("Random Forest Prediction")
print(rfCLF.predict(xBD_train))
#
#confusion matrix
print("confusion matrix for svm")
CM = confusion_matrix(y_test, svmPRED)
print(CM)

TN = CM[0][0]
FN = CM[1][0]
TP = CM[1][1]
FP = CM[0][1]

TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
FDR = FP/(TP+FP)

print("SVM TPR: ", TPR*100)
print("SVM FNR: ", FNR*100)
print("SVM FPR: ", FPR*100)
print("SVM TNR: ", TNR*100)


print("confusion matrix for knn")
CM = confusion_matrix(y_test, knnPRED)
print(CM)

TN = CM[0][0]
FN = CM[1][0]
TP = CM[1][1]
FP = CM[0][1]

TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
FDR = FP/(TP+FP)

print("KNN TPR: ", TPR*100)
print("KNN FNR: ", FNR*100)
print("KNN FPR: ", FPR*100)
print("KNN TNR: ", TNR*100)


print("confusion matrix for Decision Tree")
CM = confusion_matrix(y_test, dtPRED)
print(CM)

TN = CM[0][0]
FN = CM[1][0]
TP = CM[1][1]
FP = CM[0][1]

TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
FDR = FP/(TP+FP)

print("DT TPR: ", TPR*100)
print("DT FNR: ", FNR*100)
print("DT FPR: ", FPR*100)
print("DT TNR: ", TNR*100)

print("confusion matrix for LR")
CM = confusion_matrix(y_test, lrPRED)
print(CM)

TN = CM[0][0]
FN = CM[1][0]
TP = CM[1][1]
FP = CM[0][1]

TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
FDR = FP/(TP+FP)

print("LR TPR: ", TPR*100)
print("LR FNR: ", FNR*100)
print("LR FPR: ", FPR*100)
print("LR TNR: ", TNR*100)

print("confusion matrix for Random Forest")
CM = confusion_matrix(y_test,rfPRED)
print(CM)

TN = CM[0][0]
FN = CM[1][0]
TP = CM[1][1]
FP = CM[0][1]

TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
FDR = FP/(TP+FP)

print("RF TPR: ", TPR*100)
print("RF FNR: ", FNR*100)
print("RF FPR: ", FPR*100)
print("RF TNR: ", TNR*100)

#cross validation

scores = cross_val_score(svmCLF, x.as_matrix(), y.as_matrix(), cv=5)
print("Accuracy of SVM v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scoresLOO = cross_val_score(svmCLF , x.as_matrix(), y.as_matrix() , cv = 1189)
print("Accuracy of SVMLOO v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scores = cross_val_score(knnCLF, x.as_matrix(), y.as_matrix(), cv=5)
print("Accuracy of KNN v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scoresLOO = cross_val_score(knnCLF , x.as_matrix(), y.as_matrix() , cv = 1189)
print("Accuracy of KNNLOO v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scores = cross_val_score(dtCLF, x.as_matrix(), y.as_matrix(), cv=5)
print("Accuracy of DT v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scoresLOO = cross_val_score(dtCLF , x.as_matrix(), y.as_matrix() , cv = 1189)
print("Accuracy of DTLOO v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scores = cross_val_score(lrCLF, x.as_matrix(), y.as_matrix(), cv=5)
print("Accuracy of LR v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scoresLOO = cross_val_score(lrCLF , x.as_matrix(), y.as_matrix() , cv = 1189)
print("Accuracy of LRLOO v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scores = cross_val_score(rfCLF, x.as_matrix(), y.as_matrix(), cv=5)
print("Accuracy of RF v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

scoresLOO = cross_val_score(rfCLF , x.as_matrix(), y.as_matrix() , cv = 1189)
print("Accuracy of RFLOO v2: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))


# #
# # #shobai bcsbooster re malware bole
# #
